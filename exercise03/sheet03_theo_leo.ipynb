{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise sheet 03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Lagrange Multipliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the function $J(\\theta) = \\sum_{k}^{n} ||\\theta - x_k||^2$ with parameter $\\theta \\in \\mathbb{R}^d$:\n",
    "\n",
    "We define $\\overline{x} = \\frac{1}{n} \\sum_k^n x_k$.\n",
    "\n",
    "(a) Find $\\theta$ that minimizes $J(\\theta)$ under the constraint $\\theta^T b = 0$ with $ b \\in \\mathbb{R}^d$:\n",
    "\n",
    "$L(\\theta, \\lambda) = \\sum_{k}^{n} ||\\theta - x_k||^2 + \\lambda \\cdot (\\theta^T b)$ and $\\nabla L(\\theta, \\lambda) = \\theta^T b + \\sum_{k}^{n} \\sum_i^d 2(\\theta - x_k)_i + \\lambda b$\n",
    "\n",
    "Setting $\\nabla L(\\theta, \\lambda) = 0$ we obtain $\\theta_i = \\frac{2\\cdot n \\cdot \\overline{x}_i + \\lambda b}{\\sum_j^d b_j +2}$ \n",
    "\n",
    "Missing: Geometrical interpretation, proof that minimization is achieved by gradL = 0.\n",
    "\n",
    "(b) Find $\\theta$ that minimizes $J(\\theta)$ under the constraint $||\\theta - c||^2 = 1$ with $ c \\in \\mathbb{R}^d$:\n",
    "\n",
    "$L(\\theta, \\lambda) = \\sum_{k}^{n} ||\\theta - x_k||^2 + \\lambda \\cdot (||\\theta - c||^2 -1)$ and $\\nabla L(\\theta, \\lambda) = \\sum_k^n \\sum_i^d 2 (\\theta - x_k)_i +2 \\lambda \\sum_i^d (\\theta -c)_i -1 + \\sum_i^d (\\theta - c)_i^2$\n",
    "\n",
    "Setting $\\nabla L(\\theta, \\lambda) = 0$ we obtain $\\theta_i = -1 - c_i - \\lambda \\pm \\sqrt{2 + 2 c_i + 2 \\lambda + 4 c_i \\lambda + \\lambda^2 + 2 \\overline{x}_i \\cdot n}$\n",
    "\n",
    "Missing: Geometrical interpretation, proof that minimization is achieved by gradL = 0, result is propably false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Bounds on Eigenvalues:\n",
    "Dataset $x_n \\in \\mathbb{R}^d$, empirical mean $m = \\frac{1}{n} \\sum_k^n x_k$ and Scatter matrix $S = \\sum_k^n (x_k -m)(x_k - m)^T$\n",
    "\n",
    "With $\\lambda_1$ beeing the largest eigenvalue of $S$ and $S_{ii}$ the diagonal elements of $S$\n",
    "\n",
    "(a) Upper bounds of the eigenvalue $\\lambda_1$:\n",
    "\n",
    "With the trace beeing the sum over all eigenvalues the term $\\sum_k^n S_{ii}$ is an upper bound for $\\lambda_1$\n",
    "\n",
    "(b) Dataconditions for which the upper bound is tight:\n",
    "\n",
    "that would be that all the datavariation is along PCA1 and nothing around the Rest(?)\n",
    "\n",
    "(c) Lower bounds of the eigenvalue $\\lambda_1$:\n",
    "\n",
    "all positiv => minimum\n",
    "\n",
    "(d) Dataconditions for which the lower bound is tight:\n",
    "\n",
    "If there is no PCA(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
