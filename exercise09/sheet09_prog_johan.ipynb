{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "In this exercise sheet, you will experiment with training various support vector machines on a subset of the MNIST dataset composed of digits 5 and 6. First, download the MNIST dataset from http://yann.lecun.com/exdb/mnist/, uncompress the downloaded files, and place them in a `data/` subfolder. Install the optimization library CVXOPT (`python-cvxopt` package, or directly from the website `www.cvxopt.org`). This library will be used to optimize the dual SVM in part A.\n",
    "\n",
    "## Part A: Kernel SVM and Optimization in the Dual\n",
    "\n",
    "We would like to learn a nonlinear SVM by optimizing its dual. An advantage of the dual SVM compared to the primal SVM is that it allows to use nonlinear kernels such as the Gaussian kernel, that we define as:\n",
    "$$\n",
    "k(x,x') = \\exp \\Big( -\\frac{\\|x-x'\\|^2}{\\sigma^2} \\Big)\n",
    "$$\n",
    "The dual SVM consists of solving the following quadratic program:\n",
    "$$\n",
    "\\max_\\alpha \\sum_{i=1}^N \\alpha_i - \\frac12 \\sum_{ij} \\alpha_i \\alpha_j y_i y_j k(x_i,x_j)\n",
    "$$\n",
    "subject to:\n",
    "$$0 \\leq \\alpha_i \\leq C \\qquad \\text{and} \\qquad \\sum_{i=1}^N \\alpha_i y_i = 0.$$\n",
    "\n",
    "Then, given the alphas, the prediction of the SVM can be obtained as:\n",
    "$$\n",
    "f(x) = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 \\qquad & \\text{if} \\quad \\sum_{i=1}^N \\alpha_i y_i k(x,x_i) + \\theta > 0\\\\\n",
    "-1 \\qquad & \\text{if} \\quad \\sum_{i=1}^N \\alpha_i y_i k(x,x_i) + \\theta < 0\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\theta = \\frac{1}{\\# SV} \\sum_{i \\in SV} \\left( y_i - \\sum_{j=1}^N \\alpha_j y_j k(x_i,x_j) \\right)\n",
    "$$\n",
    "and `SV` is the set of indices corresponding to the unbound support vectors.\n",
    "\n",
    "### Implementation (25 P)\n",
    "\n",
    "We will solve the dual SVM applied to the MNIST dataset using the CVXOPT quadratic optimizer. For this, we have to build the data structures (vectors and matrices) to must be passed to the optimizer.\n",
    "\n",
    "* *Implement* a function `gaussianKernel` that returns for a Gaussian kernel of scale $\\sigma$, the Gram matrix of the two data sets given as argument.\n",
    "* *Implement* a function `getQPMatrices` that builds the matrices `P`, `q`, `G`, `h`, `A`, `b` (of type `cvxopt.matrix`) that need to be passed as argument to the optimizer `cvxopt.solvers.qp`.\n",
    "* *Run* the code below using the functions that you just implemented. (It should take less than 3 minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils,numpy,cvxopt,cvxopt.solvers,scipy.spatial\n",
    "Xtrain,Ttrain,Xtest,Ttest = utils.getMNIST56()\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain,Ttrain,Xtest,Ttest (1000, 784) (1000,) (1850, 784) (1850,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale= 10  C=  1  SV:    0  Train: 0.000  Test: 0.000\n",
      "Scale= 10  C= 10  SV: 1000  Train: 1.000  Test: 0.760\n",
      "Scale= 10  C=100  SV: 1000  Train: 1.000  Test: 0.757\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Rank(A) < p or Rank([P; A; G]) < n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArithmeticError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/cvxopt/misc.py\u001b[0m in \u001b[0;36mfactor\u001b[0;34m(W, H, Df)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                     \u001b[0mlapack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArithmeticError\u001b[0m: 5",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArithmeticError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[0;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrti\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rti'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2066\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mkktsolver\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m   1980\u001b[0m          \u001b[0;32mdef\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1981\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/cvxopt/misc.py\u001b[0m in \u001b[0;36mfactor\u001b[0;34m(W, H, Df)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                     \u001b[0mlapack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArithmeticError\u001b[0m: 24",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-93b3e043a6f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Train the model (i.e. compute the alphas)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#P,q,G,h,A,b = (P), cvxopt.matrix(q), cvxopt.matrix(G), cvxopt.matrix(h), cvxopt.matrix(A), cvxopt.matrix(b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvxopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m#alpha = numpy.where(alpha > 0, alpha, 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#print(\"alpha\", (alpha<=0).sum())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mqp\u001b[0;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[1;32m   4485\u001b[0m             'residual as dual infeasibility certificate': dinfres}\n\u001b[1;32m   4486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4487\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconeqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkktsolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[0;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2067\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rank(A) < p or Rank([P; A; G]) < n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Rank(A) < p or Rank([P; A; G]) < n"
     ]
    }
   ],
   "source": [
    "print(\"Xtrain,Ttrain,Xtest,Ttest\", Xtrain.shape,Ttrain.shape,Xtest.shape,Ttest.shape)\n",
    "\n",
    "def gaussianKernel(X1, X2, sigma):\n",
    "    return numpy.exp(-scipy.spatial.distance.cdist(X1, X2, 'euclidean')**2/sigma**2)\n",
    "\n",
    "def getQPMatrices(K, T, C):\n",
    "    ones = numpy.ones(K.shape[0])\n",
    "    zeros = ones*.0\n",
    "    \n",
    "    # maximizer: therefore negative minimizer\n",
    "    Y = numpy.outer(T, T)\n",
    "    P = -Y*K #numpy.diag(numpy.ones(K.shape[0]))\n",
    "    q = numpy.ones(K.shape[0])\n",
    "    \n",
    "    # constraint: 0 ≤ a_i ≤ C\n",
    "    G = numpy.concatenate([numpy.diag(ones), -numpy.diag(ones)])\n",
    "    h = numpy.concatenate([C*ones, zeros])\n",
    "    \n",
    "    # constraint: sum a_i*y_i = 0\n",
    "    A = T.reshape(1,-1)\n",
    "    b = .0\n",
    "\n",
    "    return map(cvxopt.matrix, (P, q, G, h, A, b))\n",
    "\n",
    "for scale in [10,30,100]:\n",
    "    for C in [1,10,100]:\n",
    "\n",
    "        # Prepare kernel matrices\n",
    "        Ktrain = gaussianKernel(Xtrain, Xtrain, scale)\n",
    "        Ktest  = gaussianKernel(Xtest, Xtrain, scale)     \n",
    "     \n",
    "        # Prepare the matrices for the quadratic program\n",
    "        P,q,G,h,A,b = getQPMatrices(Ktrain, Ttrain, C)\n",
    "        \n",
    "        # Train the model (i.e. compute the alphas)\n",
    "        #P,q,G,h,A,b = (P), cvxopt.matrix(q), cvxopt.matrix(G), cvxopt.matrix(h), cvxopt.matrix(A), cvxopt.matrix(b)\n",
    "        alpha = numpy.array(cvxopt.solvers.qp(P,q,G,h,A,b)['x']).flatten()\n",
    "        #alpha = numpy.where(alpha > 0, alpha, 0)\n",
    "        #print(\"alpha\", (alpha<=0).sum())\n",
    "        \n",
    "        # Get predictions for the training and test set\n",
    "        SV = (alpha>1e-6)\n",
    "        uSV = SV*(alpha<C-1e-6)\n",
    "        theta = 1.0/sum(uSV)*(Ttrain[uSV]-numpy.dot(Ktrain[uSV,:],alpha*Ttrain)).sum()\n",
    "        Ytrain = numpy.sign(numpy.dot(Ktrain[:,SV],alpha[SV]*Ttrain[SV])+theta)\n",
    "        Ytest  = numpy.sign(numpy.dot(Ktest [:,SV],alpha[SV]*Ttrain[SV])+theta)\n",
    "        \n",
    "        # Print accuracy and number of support vectors\n",
    "        Atrain = (Ytrain == Ttrain).mean()\n",
    "        Atest  = (Ytest == Ttest).mean()\n",
    "        print('Scale=%3d  C=%3d  SV: %4d  Train: %.3f  Test: %.3f'%(scale,C,sum(SV),Atrain,Atest))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis (10 P)\n",
    "\n",
    "* *Explain* which combinations of parameters $\\sigma$ and $C$ lead to good generalization, underfitting or overfitting?\n",
    "\n",
    "* *Explain* which combinations of parameters $\\sigma$ and $C$ produce the fastest classifiers (in terms of amount of computation needed at prediction time)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Linear SVMs and Gradient Descent in the Primal\n",
    "\n",
    "The quadratic problem of the dual SVM does not scale well with the number of data points. For large number of data points, it is generally more appropriate to optimize the SVM in the primal. The primal optimization problem for linear SVMs can be written as\n",
    "$$\\min_{w,\\theta} ||w||^2 + C \\sum_{i=1}^N \\xi_i \\qquad \\text{where} \\qquad \\forall_{i=1}^N: y_i (w \\cdot x_i+\\theta) \\geq 1-\\xi_i \\qquad \\text{and} \\qquad \\xi_i \\geq 0.$$\n",
    "It is common to incorporate the constraints directly into the objective and then minimizing the unconstrained objective\n",
    "$$\\qquad J(w,\\theta) = ||w||^2 +C \\sum_{i=1}^N \\max(0,1-y_i (w \\cdot x_i + \\theta))$$\n",
    "using simple gradient descent.\n",
    "\n",
    "### Implementation (15 P)\n",
    "\n",
    "* *Implement* the function `J` computing the objective $J(w,\\theta)$\n",
    "* *Implement* the function `DJ` computing the gradient of the objective $J(w,\\theta)$ with respect to the parameters $w$ and $\\theta$.\n",
    "* *Run* the code below using the functions that you just implemented. (It should take less than 1 minute.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'solutions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5b51140833de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'solutions'"
     ]
    }
   ],
   "source": [
    "import utils,numpy\n",
    "import solutions\n",
    "\n",
    "C = 10.0\n",
    "lr = 0.001\n",
    "\n",
    "Xtrain,Ttrain,Xtest,Ttest = utils.getMNIST56()\n",
    "\n",
    "n,d = Xtrain.shape\n",
    "\n",
    "w = numpy.zeros([d])\n",
    "theta = 1e-9\n",
    "\n",
    "for it in range(0,101):\n",
    "    \n",
    "    # Monitor the training and test error every 5 iterations\n",
    "    if it%5==0:\n",
    "        Ytrain = numpy.sign(numpy.dot(Xtrain,w)+theta)\n",
    "        Ytest  = numpy.sign(numpy.dot(Xtest ,w)+theta)\n",
    "        \n",
    "        ### TODO: REPLACE BY YOUR OWN CODE\n",
    "        Obj    = solutions.J(w,theta,C,Xtrain,Ttrain)\n",
    "        ###\n",
    "        \n",
    "        Etrain = (Ytrain==Ttrain).mean()\n",
    "        Etest  = (Ytest ==Ttest ).mean()\n",
    "        print('It=%3d   J: %9.3f  Train: %.3f  Test: %.3f'%(it,Obj,Etrain,Etest))\n",
    "\n",
    "    ### TODO: REPLACE BY YOUR OWN CODE\n",
    "    dw,dtheta = solutions.DJ(w,theta,C,Xtrain,Ttrain)\n",
    "    ###\n",
    "    \n",
    "    w = w - lr*dw\n",
    "    theta = theta - lr*dtheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
